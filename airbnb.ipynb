{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO ACTIVATE VIRTUAL ENVIRONMENT \n",
    ".\\myenv\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymongo\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data extraction and Data gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('C:/Users/nkn05/OneDrive/Desktop/CSV DATA/Data/sample_airbnb.json', 'r') as f:\n",
    "    data1 = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[0:,'access':'images']\n",
    "df1.loc[0:,'access':'number_of_reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[0:,'last_scraped':'last_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding extra columns to the dataframe\n",
    "\n",
    "# Convert to datetime\n",
    "df1['last_scraped'] = pd.to_datetime(df1['last_scraped'])\n",
    "df1['calendar_last_scraped'] = pd.to_datetime(df1['calendar_last_scraped'])\n",
    "df1['first_review'] = pd.to_datetime(df1['first_review'])\n",
    "df1['last_review'] = pd.to_datetime(df1['last_review'])\n",
    "\n",
    "# Split datetime into separate date and time columns\n",
    "df1['last_scraped_date'] = df1['last_scraped'].dt.date\n",
    "df1['last_scraped_time'] = df1['last_scraped'].dt.time\n",
    "\n",
    "df1['calendar_last_scraped_date'] = df1['calendar_last_scraped'].dt.date\n",
    "df1['calendar_last_scraped_time'] = df1['calendar_last_scraped'].dt.time\n",
    "\n",
    "df1['first_review_date'] = df1['first_review'].dt.date\n",
    "df1['first_review_time'] = df1['first_review'].dt.time\n",
    "\n",
    "df1['last_review_date'] = df1['last_review'].dt.date\n",
    "df1['last_review_time'] = df1['last_review'].dt.time\n",
    "\n",
    "# Drop original datetime columns if needed\n",
    "df1.drop(columns=['last_scraped', 'calendar_last_scraped', 'first_review', 'last_review'], inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting reviews details seperately\n",
    "reviews_details=df1.loc[0:,['_id','reviews_per_month','last_scraped_date','last_scraped_time','calendar_last_scraped_date','calendar_last_scraped_time','first_review_date','first_review_time',\n",
    "                            'last_review_date','last_review_time' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_details.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns \n",
    "df1.drop(columns=['last_scraped_date','last_scraped_time','calendar_last_scraped_date','calendar_last_scraped_time','first_review_date','last_review_time','first_review_time']\n",
    "         ,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[0:,'host':'reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize nested columns\n",
    "host_df = json_normalize(df1['host'])\n",
    "address_df = json_normalize(df1['address'])\n",
    "availability_df = json_normalize(df1['availability'])\n",
    "review_scores_df = json_normalize(df1['review_scores'])\n",
    "\n",
    "# Concatenate normalized columns back to the original DataFrame\n",
    "df1 = pd.concat([df1.drop(['host', 'address', 'availability', 'review_scores'], axis=1),\n",
    "                host_df, address_df, availability_df, review_scores_df], axis=1)\n",
    "\n",
    "# Display the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_df['host_neighbourhood'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_df['host_neighbourhood'].fillna('Not Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_df['host_neighbourhood'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_df['host_neighbourhood'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[['location.coordinates','_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'location.coordinates' column into 'longitude' and 'latitude'\n",
    "df1[['longitude', 'latitude']] = pd.DataFrame(df1['location.coordinates'].tolist(), index=df1.index)\n",
    "\n",
    "# Drop the original 'location.coordinates' column\n",
    "df1.drop(columns=['location.coordinates'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Address=['_id','street','suburb','government_area','market','country','country_code','location.type','location.is_location_exact','longitude','latitude']\n",
    "\n",
    "Address_details=df1[Address]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "host=['_id','host_id','host_url','host_name','host_location','host_about','host_response_time','host_thumbnail_url','host_picture_url','host_neighbourhood',\n",
    "              'host_response_rate','host_is_superhost','host_has_profile_pic','host_identity_verified','host_listings_count','host_total_listings_count','host_verifications']\n",
    "\n",
    "host_details=df1[host]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Address_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Address_details['market'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Address_details['market'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Address_details['market'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_scores_df['_id']=df1['_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After viewing the multiple columns in the listings.csv from the data_description.txt, \n",
    "# the following variables were picked for further analysis and dropped variables like date_scraped etc.\n",
    "listingDF = df1[['_id','name','summary','longitude','latitude','space','description','host_neighbourhood','host_id','host_name','last_review_date','street',\n",
    "                 'host_response_time','street','country','review_scores_rating','property_type','room_type','accommodates','bathrooms','bedrooms','beds','reviews_per_month','amenities','cancellation_policy','number_of_reviews','price']]\n",
    "listingDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Id: Unique identifier for each listing.\n",
    "\n",
    "# Name: The title or name of the listing.\n",
    "\n",
    "# Host Id: Unique identifier for the host of the listing.\n",
    "\n",
    "# Host Name: The name of the host.\n",
    "\n",
    "# Neighbourhood: The specific neighborhood where the listing is located.\n",
    "\n",
    "# Latitude: The latitude coordinate of the listing's location.\n",
    "\n",
    "# Longitude: The longitude coordinate of the listing's location.\n",
    "\n",
    "# Room Type: The type of room being listed (e.g., \"Entire home/apartment\", \"Private room\", \"Shared room\").\n",
    "\n",
    "# Price: The price to rent the listing.\n",
    "\n",
    "# Minimum Nights: The minimum number of nights a guest must book for the listing.\n",
    "\n",
    "# Maximum Nights: The Maximun number of nights a guest must book for the listing.\n",
    "\n",
    "# Number Of Reviews: The total number of reviews the listing has received.\n",
    "\n",
    "# Availability 30: The number of days the listing is available for booking within the next 30 days\n",
    "\n",
    "# Availability 60: The number of days the listing is available for booking within the next 60 days\n",
    "\n",
    "# Availability 90: The number of days the listing is available for booking within the next 90 days\n",
    "\n",
    "# Availability 365: The number of days the listing is available for booking within the next 365 days\n",
    "\n",
    "# Rating : ratings given by guests to the listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After viewing the multiple columns in the listings.csv from the data_description.txt, \n",
    "# the following variables were picked for further analysis and dropped variables like date_scraped etc.\n",
    "listingDF = df1[['_id','name','summary','longitude','latitude','host_neighbourhood','host_id','host_name','last_review_date',\n",
    "                 'host_response_time','street','suburb','government_area','market','country','review_scores_rating','property_type','room_type','accommodates','bathrooms','bedrooms','beds','amenities','cancellation_policy','minimum_nights',\n",
    "             'maximum_nights',\n",
    "             'availability_30',\n",
    "             'availability_60',\n",
    "             'availability_90',\n",
    "             'availability_365','number_of_reviews','price']]\n",
    "listingDF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After viewing the multiple columns in the listings.csv from the data_description.txt, \n",
    "# the following variables were picked for further analysis and dropped variables like date_scraped etc\n",
    "new_column_names={'_id' : 'Id',\n",
    "             'name': 'Name',\n",
    "             'host_id': 'Host Id',\n",
    "             'host_name' : 'Host Name',\n",
    "             'host_response_time' : 'Host Response Time',\n",
    "             'last_review_date':'Last Review',\n",
    "             'street':'Street',\n",
    "             'government_area':'Government Area',\n",
    "             'suburb':'Suburban',\n",
    "             'market':'Market',\n",
    "             'country' : 'Country',\n",
    "             'space' : 'Space',\n",
    "             'description': 'Description',\n",
    "             'host_neighbourhood': 'Neighborhood',\n",
    "             'latitude' : 'Latitude',\n",
    "             'longitude' : 'Longitude',\n",
    "             'room_type' : 'Room Type',\n",
    "             'property_type': 'Property Type',\n",
    "             'accommodates' : 'Accomodates',\n",
    "             'bathrooms' : 'Bathrooms',\n",
    "             'bedrooms' : 'Bedrooms',\n",
    "             'amenities' : 'Amenities',\n",
    "             'cancellation_policy':'Cancellation Policy',\n",
    "             'price':'Price',\n",
    "             'minimum_nights':'Minumum Nights',\n",
    "             'maximum_nights':'Maximum Nights',\n",
    "             'number_of_reviews':'No of Reviews',\n",
    "             'availability_30' : 'Availability 30',\n",
    "             'availability_60' : 'Availability 60',\n",
    "             'availability_90' : 'Availability_90',\n",
    "             'availability_365' : 'Availability_365',\n",
    "             'review_scores_rating': 'Rating'}\n",
    "\n",
    "# Rename columns\n",
    "listingDF.rename(columns=new_column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listingDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listingDF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data=listingDF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quickly explore the data\n",
    "air_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing Data Types\n",
    "\n",
    "air_data['Maximum Nights']=air_data['Maximum Nights'].astype('int64')\n",
    "\n",
    "air_data['Minumum Nights']=air_data['Minumum Nights'].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data['Room Type']=air_data['Room Type'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(air_data['Last Review'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data['Room Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identifying missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data.Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data[air_data.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data['Neighborhood'].fillna('UnKnown',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data['Neighborhood'].replace('','Not Provided',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data['Neighborhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Last Review' column to datetime\n",
    "air_data['Last Review'] = pd.to_datetime(air_data['Last Review'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the month from the 'Last Review' column\n",
    "air_data['Month'] = air_data['Last Review'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data['summary'].replace('','Not Provided',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data['Market'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data['Market'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data['Suburban'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data['Suburban'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data['Government Area'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data[['Rating','No of Reviews']].head(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data.loc[air_data['Rating'].isna()].tail(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if No of reviews 0 or less revies then rating of the listing having Nan values ,that means if reviews are less or not given by the cus then ratings are not calculated\n",
    "# If the number of reviews is zero, the rating should remain NaN because there's no basis for imputing a rating. However, we can handle cases where the number of reviews is very low (e.g., 1-2 reviews) differently from those with a substantial number of reviews.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define review bins excluding 0 and 1-2 reviews\n",
    "bins = [2, 5, 10, 20, 50, 100, float('inf')]\n",
    "labels = ['3-5', '6-10', '11-20', '21-50', '51-100', '101+']\n",
    "\n",
    "#copy the dataframe for further Edits in the Dataframe\n",
    "\n",
    "airdata1=air_data.copy()\n",
    "\n",
    "# Create a new column for review bins\n",
    "airdata1['Review Bin'] = pd.cut(airdata1['No of Reviews'], bins=bins, labels=labels,right=False)\n",
    "\n",
    "# Calculate the mean rating for each review bin\n",
    "mean_ratings = airdata1.groupby('Review Bin')['Rating'].mean()\n",
    "\n",
    "# Mean rating for 1-2 reviews\n",
    "mean_low_reviews = airdata1[airdata1['No of Reviews'].isin([1, 2])]['Rating'].mean()\n",
    "\n",
    "# Fill NaN values in the Rating column based on the mean rating of the corresponding review bin\n",
    "def fill_rating(row):\n",
    "    if pd.isna(row['Rating']):\n",
    "        if row['No of Reviews'] == 0:\n",
    "            return np.nan  # Keep as NaN\n",
    "        elif row['No of Reviews'] in [1, 2]:\n",
    "            return mean_low_reviews  # Use mean rating for 1-2 reviews\n",
    "        else:\n",
    "            return mean_ratings[row['Review Bin']]\n",
    "    else:\n",
    "        return row['Rating']\n",
    "    \n",
    "airdata1['Rating'] = airdata1.apply(fill_rating, axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdata1['Rating'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_data.loc[air_data['Rating'].isna()].tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdata1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdata1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdata1.drop(columns='Review Bin',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdata1[airdata1['Rating'].notna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdata1['Rating'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#but still large number of missing values in the column rating,so imputing all values with a 0 in an rating column\n",
    "airdata1['Rating']=airdata1.apply(lambda row:0 if pd.isna(row['Rating'])  else row['Rating'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdata1['Rating'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdata1.Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdata1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdata1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdata1['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdata1['Host Name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling incorrect text  & typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdata1['Amenities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdata1['Amenities']=airdata1['Amenities'].apply(lambda x : ', '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There was no duplicated data\n",
    "airdata1.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#identifying outliers using IQR METHOD\n",
    "\n",
    "# Load your dataset\n",
    "# Select numerical columns\n",
    "numerical_columns = airdata1.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "def detect_outliers_iqr(df, columns):\n",
    "    outliers_list = []  # Store DataFrames with outliers here\n",
    "\n",
    "    for column in columns:\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Find outliers\n",
    "        outlier_indices = df[(df[column] < lower_bound) | (df[column] > upper_bound)].index\n",
    "        outliers_list.append(df.loc[outlier_indices])\n",
    "\n",
    "    # Concatenate all the outliers into one DataFrame\n",
    "    outliers = pd.concat(outliers_list).drop_duplicates()\n",
    "    return outliers\n",
    "\n",
    "\n",
    "# Detect outliers\n",
    "outliers = detect_outliers_iqr(airdata1, numerical_columns)\n",
    "\n",
    "# Print the outliers\n",
    "print(f\"Total outliers found: {len(outliers)}\")\n",
    "#print(outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# Function to detect outliers using Z-score method\n",
    "def detect_outliers_zscore(df, columns, threshold=3):\n",
    "    outliers_z_list=[]\n",
    "\n",
    "    for column in columns:\n",
    "        z_scores = zscore(df[column])\n",
    "        outlier_indices = df[(abs(z_scores) > threshold)].index\n",
    "        outliers_z_list.append(df.loc[outlier_indices])\n",
    "\n",
    "    # Drop duplicates\n",
    "    outliers = pd.concat(outliers_z_list).drop_duplicates()\n",
    "    return outliers\n",
    "\n",
    "# Detect outliers\n",
    "outliers_z = detect_outliers_zscore(airdata1, numerical_columns)\n",
    "\n",
    "# Print the outliers\n",
    "print(f\"Total outliers found using Z-score: {len(outliers_z)}\")\n",
    "print(outliers_z.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outliers by visualization using Box plot\n",
    "numerical_columns = airdata1.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Plot each numerical column individually\n",
    "for column in numerical_columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=airdata1[column])\n",
    "    plt.title(f'Box Plot for {column}')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using scatter plot\n",
    "\n",
    "\n",
    "numerical_columns = airdata1.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Plot each numerical column individually\n",
    "for column in numerical_columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=airdata1.index,y=airdata1[column])\n",
    "    plt.title(f'Scatter Plot for {column}')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_columns = airdata1.select_dtypes(include=['float64', 'int64']).columns\n",
    "num_data = airdata1[numerical_columns]\n",
    "\n",
    "# Check for NaN values and handle them by filling with the mean\n",
    "num_data_filled = num_data.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "\n",
    "\n",
    "#Ensure all the data which have datatypes(int or float)\n",
    "\n",
    "num_data_filled=num_data_filled.astype('float64')\n",
    "\n",
    "\n",
    "print(\"\\nProcessed numerical data for Z-score calculation:\\n\", num_data_filled)\n",
    "\n",
    "def remove_outliers_zscore(data, threshold=2):\n",
    "    #computing zscore but ignoring NAN values(they will stay as Nan)\n",
    "    z_score = np.abs(stats.zscore(data,nan_policy='omit'))\n",
    "\n",
    "    # set nan values as 0 for zscore\n",
    "    z_score=np.where(np.isnan(z_score),0,z_score)\n",
    "\n",
    "    # Filter rows where all z-scores are below the threshold\n",
    "    filter_outliers = (z_score < threshold).all(axis=1)\n",
    "    return filter_outliers\n",
    "\n",
    "# Filter to remove outliers from numerical data\n",
    "outlier_filter = remove_outliers_zscore(num_data_filled)\n",
    "\n",
    "\n",
    "# Apply the filter to the original DataFrame to keep all columns\n",
    "cleaned_df_using_zscore = airdata1[outlier_filter]\n",
    "\n",
    "print(\"\\nCleaned DataFrame using Z-Score method:\\n\", cleaned_df_using_zscore.head())\n",
    "print(len(cleaned_df_using_zscore))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_using_zscore.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_using_zscore.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_using_zscore.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdata1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdata1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdata1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('comparing removing outilers data vs orginal data')\n",
    "print('\\n')\n",
    "print('ORGINAL DATA : \\n',airdata1.head(5))\n",
    "\n",
    "print('Removing outliers Using zscore : \\n',cleaned_df_using_zscore.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdata1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_using_zscore.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here i have taken airdata dataset for further analysis,Since after outliers dataset removing around 800 rows which have some important insights,so i keep the outliers which not impacted my furthere analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating\n",
       "0.000000      1388\n",
       "100.000000     982\n",
       "98.000000      291\n",
       "96.000000      286\n",
       "97.000000      281\n",
       "95.000000      259\n",
       "93.000000      244\n",
       "94.000000      223\n",
       "90.000000      213\n",
       "99.000000      188\n",
       "80.000000      167\n",
       "92.000000      158\n",
       "89.000000      113\n",
       "91.000000      112\n",
       "87.000000       97\n",
       "91.083223       83\n",
       "88.000000       77\n",
       "85.000000       55\n",
       "86.000000       48\n",
       "84.000000       43\n",
       "60.000000       41\n",
       "83.000000       39\n",
       "70.000000       25\n",
       "82.000000       19\n",
       "20.000000       16\n",
       "81.000000       12\n",
       "75.000000       11\n",
       "78.000000       11\n",
       "40.000000       10\n",
       "76.000000        9\n",
       "79.000000        8\n",
       "73.000000        8\n",
       "67.000000        5\n",
       "72.000000        5\n",
       "74.000000        5\n",
       "71.000000        4\n",
       "77.000000        4\n",
       "65.000000        3\n",
       "68.000000        3\n",
       "92.658699        3\n",
       "69.000000        2\n",
       "50.000000        2\n",
       "53.000000        1\n",
       "64.000000        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airdata1['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1989    48842.0\n",
       "878     11681.0\n",
       "3435    11681.0\n",
       "739     11190.0\n",
       "2453    10001.0\n",
       "         ...   \n",
       "3940     1601.0\n",
       "336      1600.0\n",
       "3309     1586.0\n",
       "1016     1562.0\n",
       "3571     1550.0\n",
       "Name: Price, Length: 100, dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airdata1['Price'].nlargest(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>summary</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Host Id</th>\n",
       "      <th>Host Name</th>\n",
       "      <th>Last Review</th>\n",
       "      <th>Host Response Time</th>\n",
       "      <th>...</th>\n",
       "      <th>Cancellation Policy</th>\n",
       "      <th>Minumum Nights</th>\n",
       "      <th>Maximum Nights</th>\n",
       "      <th>Availability 30</th>\n",
       "      <th>Availability 60</th>\n",
       "      <th>Availability_90</th>\n",
       "      <th>Availability_365</th>\n",
       "      <th>No of Reviews</th>\n",
       "      <th>Price</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>20275354</td>\n",
       "      <td>İstanbul un kalbi sisli. Center of istanbul sisli</td>\n",
       "      <td>We are new married couple.We have have one fully furnished single room for rent in our flat which is located in Sisli Bomonti. The room is fully furnished, recently painted and large enough for on...</td>\n",
       "      <td>28.98111</td>\n",
       "      <td>41.05465</td>\n",
       "      <td>Not Provided</td>\n",
       "      <td>118695718</td>\n",
       "      <td>Ipek</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>flexible</td>\n",
       "      <td>2</td>\n",
       "      <td>1125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48842.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>20287455</td>\n",
       "      <td>Peaceful Refuge in Central Kona</td>\n",
       "      <td>Enjoy yourself in this bright, airy and clean guest house with it's colorful island decor, beautiful garden surroundings, and peak-a-boo view of the ocean.    Located almost directly above the Hon...</td>\n",
       "      <td>-155.98335</td>\n",
       "      <td>19.67595</td>\n",
       "      <td>Kailua/Kona</td>\n",
       "      <td>99589042</td>\n",
       "      <td>Carol</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>...</td>\n",
       "      <td>strict_14_with_grace_period</td>\n",
       "      <td>2</td>\n",
       "      <td>1125</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>196</td>\n",
       "      <td>37</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>20396803</td>\n",
       "      <td>Chammbre lit queen</td>\n",
       "      <td>Chambre dans un 61/2 en collocation. Appartement situé à 1 min de la plaza saint hubert (boutiques,resto,bars,et plus) et à moins de 5 min à pieds de la station rosemont. Diverses épiceries aux al...</td>\n",
       "      <td>-73.59951</td>\n",
       "      <td>45.53298</td>\n",
       "      <td>La Petite-Patrie</td>\n",
       "      <td>31521169</td>\n",
       "      <td>Majestik</td>\n",
       "      <td>2017-09-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>strict_14_with_grace_period</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id                                               Name  \\\n",
       "1989  20275354  İstanbul un kalbi sisli. Center of istanbul sisli   \n",
       "1990  20287455                    Peaceful Refuge in Central Kona   \n",
       "1991  20396803                                 Chammbre lit queen   \n",
       "\n",
       "                                                                                                                                                                                                      summary  \\\n",
       "1989  We are new married couple.We have have one fully furnished single room for rent in our flat which is located in Sisli Bomonti. The room is fully furnished, recently painted and large enough for on...   \n",
       "1990  Enjoy yourself in this bright, airy and clean guest house with it's colorful island decor, beautiful garden surroundings, and peak-a-boo view of the ocean.    Located almost directly above the Hon...   \n",
       "1991  Chambre dans un 61/2 en collocation. Appartement situé à 1 min de la plaza saint hubert (boutiques,resto,bars,et plus) et à moins de 5 min à pieds de la station rosemont. Diverses épiceries aux al...   \n",
       "\n",
       "      Longitude  Latitude      Neighborhood    Host Id Host Name Last Review  \\\n",
       "1989   28.98111  41.05465      Not Provided  118695718      Ipek         NaT   \n",
       "1990 -155.98335  19.67595       Kailua/Kona   99589042     Carol  2019-02-11   \n",
       "1991  -73.59951  45.53298  La Petite-Patrie   31521169  Majestik  2017-09-06   \n",
       "\n",
       "     Host Response Time  ...          Cancellation Policy Minumum Nights  \\\n",
       "1989                NaN  ...                     flexible              2   \n",
       "1990     within an hour  ...  strict_14_with_grace_period              2   \n",
       "1991                NaN  ...  strict_14_with_grace_period              6   \n",
       "\n",
       "     Maximum Nights Availability 30 Availability 60  Availability_90  \\\n",
       "1989           1125               0               0                0   \n",
       "1990           1125              15              32               32   \n",
       "1991             18               0               0                0   \n",
       "\n",
       "     Availability_365 No of Reviews    Price  Month  \n",
       "1989                0             0  48842.0    NaN  \n",
       "1990              196            37     65.0    2.0  \n",
       "1991                0             2     30.0    9.0  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airdata1.iloc[1989:1992]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdata1.drop(index=1989,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Last Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Accomodates</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>Minumum Nights</th>\n",
       "      <th>Maximum Nights</th>\n",
       "      <th>Availability 30</th>\n",
       "      <th>Availability 60</th>\n",
       "      <th>Availability_90</th>\n",
       "      <th>Availability_365</th>\n",
       "      <th>No of Reviews</th>\n",
       "      <th>Price</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5554.000000</td>\n",
       "      <td>5554.000000</td>\n",
       "      <td>4167</td>\n",
       "      <td>5554.000000</td>\n",
       "      <td>5554.000000</td>\n",
       "      <td>5544.000000</td>\n",
       "      <td>5549.000000</td>\n",
       "      <td>5541.000000</td>\n",
       "      <td>5554.0</td>\n",
       "      <td>5.554000e+03</td>\n",
       "      <td>5554.000000</td>\n",
       "      <td>5554.000000</td>\n",
       "      <td>5554.000000</td>\n",
       "      <td>5554.000000</td>\n",
       "      <td>5554.000000</td>\n",
       "      <td>5554.000000</td>\n",
       "      <td>4167.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-6.629651</td>\n",
       "      <td>22.057810</td>\n",
       "      <td>2018-08-15 15:35:07.127429632</td>\n",
       "      <td>69.819208</td>\n",
       "      <td>3.506302</td>\n",
       "      <td>1.291216</td>\n",
       "      <td>1.411786</td>\n",
       "      <td>2.071648</td>\n",
       "      <td>5.564998</td>\n",
       "      <td>1.383025e+06</td>\n",
       "      <td>11.818329</td>\n",
       "      <td>26.456068</td>\n",
       "      <td>42.765754</td>\n",
       "      <td>173.136838</td>\n",
       "      <td>27.611451</td>\n",
       "      <td>270.022326</td>\n",
       "      <td>4.692825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-159.678690</td>\n",
       "      <td>-34.088290</td>\n",
       "      <td>2012-01-06 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-73.599540</td>\n",
       "      <td>20.724380</td>\n",
       "      <td>2018-08-08 00:00:00</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.900000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-8.611465</td>\n",
       "      <td>40.726990</td>\n",
       "      <td>2019-01-02 00:00:00</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.125000e+03</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>171.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.019703</td>\n",
       "      <td>41.162813</td>\n",
       "      <td>2019-02-15 00:00:00</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.125000e+03</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151.338980</td>\n",
       "      <td>45.665630</td>\n",
       "      <td>2019-03-11 00:00:00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>533.000000</td>\n",
       "      <td>11681.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>90.532863</td>\n",
       "      <td>28.093484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.021265</td>\n",
       "      <td>2.296980</td>\n",
       "      <td>0.702317</td>\n",
       "      <td>1.042022</td>\n",
       "      <td>1.619743</td>\n",
       "      <td>22.615846</td>\n",
       "      <td>5.257393e+07</td>\n",
       "      <td>11.686089</td>\n",
       "      <td>23.475440</td>\n",
       "      <td>35.225395</td>\n",
       "      <td>139.835186</td>\n",
       "      <td>49.801481</td>\n",
       "      <td>533.547676</td>\n",
       "      <td>3.885014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Longitude     Latitude                    Last Review       Rating  \\\n",
       "count  5554.000000  5554.000000                           4167  5554.000000   \n",
       "mean     -6.629651    22.057810  2018-08-15 15:35:07.127429632    69.819208   \n",
       "min    -159.678690   -34.088290            2012-01-06 00:00:00     0.000000   \n",
       "25%     -73.599540    20.724380            2018-08-08 00:00:00    20.000000   \n",
       "50%      -8.611465    40.726990            2019-01-02 00:00:00    92.000000   \n",
       "75%      29.019703    41.162813            2019-02-15 00:00:00    98.000000   \n",
       "max     151.338980    45.665630            2019-03-11 00:00:00   100.000000   \n",
       "std      90.532863    28.093484                            NaN    41.021265   \n",
       "\n",
       "       Accomodates    Bathrooms     Bedrooms         beds  Minumum Nights  \\\n",
       "count  5554.000000  5544.000000  5549.000000  5541.000000          5554.0   \n",
       "mean      3.506302     1.291216     1.411786     2.071648        5.564998   \n",
       "min       1.000000     0.000000     0.000000     0.000000             1.0   \n",
       "25%       2.000000     1.000000     1.000000     1.000000             1.0   \n",
       "50%       3.000000     1.000000     1.000000     2.000000             2.0   \n",
       "75%       4.000000     1.000000     2.000000     3.000000             3.0   \n",
       "max      16.000000    16.000000    20.000000    25.000000          1250.0   \n",
       "std       2.296980     0.702317     1.042022     1.619743       22.615846   \n",
       "\n",
       "       Maximum Nights  Availability 30  Availability 60  Availability_90  \\\n",
       "count    5.554000e+03      5554.000000      5554.000000      5554.000000   \n",
       "mean     1.383025e+06        11.818329        26.456068        42.765754   \n",
       "min      1.000000e+00         0.000000         0.000000         0.000000   \n",
       "25%      5.900000e+01         0.000000         0.000000         0.000000   \n",
       "50%      1.125000e+03         8.000000        23.000000        43.000000   \n",
       "75%      1.125000e+03        24.000000        52.000000        80.000000   \n",
       "max      2.147484e+09        30.000000        60.000000        90.000000   \n",
       "std      5.257393e+07        11.686089        23.475440        35.225395   \n",
       "\n",
       "       Availability_365  No of Reviews         Price        Month  \n",
       "count       5554.000000    5554.000000   5554.000000  4167.000000  \n",
       "mean         173.136838      27.611451    270.022326     4.692825  \n",
       "min            0.000000       0.000000      9.000000     1.000000  \n",
       "25%           17.000000       1.000000     70.000000     2.000000  \n",
       "50%          171.500000       5.000000    129.000000     2.000000  \n",
       "75%          317.000000      32.000000    280.000000     8.000000  \n",
       "max          365.000000     533.000000  11681.000000    12.000000  \n",
       "std          139.835186      49.801481    533.547676     3.885014  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airdata1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving csv file for further analysis\n",
    "\n",
    "listing_df=airdata1.to_csv('listingDF.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
